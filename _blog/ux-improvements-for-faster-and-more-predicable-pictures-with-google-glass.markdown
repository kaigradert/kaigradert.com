---
title: Usability Improvements for Faster & More Predicable Pictures With Google Glass
date: 2013-07-15 00:02:00 Z
tags:
- design
- thoughts
---

The camera has quickly become the stand-out feature for me after using Google Glass (XE6 and XE7) extensively for the past few weeks.

The ability to capture hands-free and candid [in the moment](/blog/cycling-from-san-francisco-to-los-angeles-with-google-glass/) shots is a strong use case. There are however a few usability improvements that would make taking pictures and videos with Glass even faster and more predictable.

<figure>
<img src="/uploads/Google-Glass-Viewfinder-Before-After.jpg" alt="Google Glass Take a Picture with Live Viewfinder">
<figcaption>Before: <strong>Solid Black</strong> and After: <strong>Live Viewfinder</strong></figcaption>
</figure>

#### Suggestion: Live Viewfinder

A lot of times I end up taking multiple photos of the same scene because the photo didn't come out the way I expected it.

That is because my line of vision is not always aligned with the Glass camera. The human field of view is also much greater than the projected display, so it is inevitable that you won't capture the entire view.

Adding a simple live viewfinder to the *“Take a picture”* and *“Record a video”* timeline card will allow the user to get more predictable results on the first take. It enables the user to adjust the position of the camera (their head) before taking the appropriate action.

<figure>
<img src="/uploads/Google-Glass-Take-a-Picture-Live-Viewfinder.jpg" alt="">
<figcaption><em>“Take a picture”</em> card with live viewfinder</figcaption>
</figure>

<figure>
<img src="/uploads/Google-Glass-Record-a-Video-Live-Viewfinder.jpg" alt="">
<figcaption><em>“Record a video”</em> card with live viewfinder</figcaption>
</figure>

<!--
#### Problems With Cognitive Complexity

Google Glass has multiple ways to access the camera through voice and touch commands. Each one of them requires the user to go through multiple (cognitive) steps:

##### Touch: 4 to 5 Steps

1. Wake up hardware (tap or tilt head gesture)
2. Tap *“OK Glass”*
3. Slide forward once to *“Take a Picture”* (or twice to *“Record a video”*)
4. Tap to perform action

##### Voice: 3 Steps

1. Wake up hardware (tap or tilt head gesture)
2. Say *“OK Glass”*
3. Say *“Take a picture”* or *“Record a video”*

##### Manual Shutter: 3 Steps

1. Move hand up
2. Locate small shutter button on the frame
3. Press finger down to *“Take a Picture”* (or press & hold to *”Record a video"”*)

Out of the three, I find the manual shutter button is the fastest and least intrusive options. But even using the manual shutter button draws attention in public because you don't generally see people touching or holding their eyewear frames.

To speed up the task of taking pictures and videos when the device is asleep, I would love to have a single unobtrusive gesture to complete the task.
-->

#### Suggestion: Instant Photo Gesture

Google Glass has multiple ways to access the camera through a manual shutter, voice and touch commands. Each one of them requires the user to go through multiple (cognitive) steps.

To speed up the task of taking pictures and videos when the device is asleep, I would love to have a single unobtrusive gesture to complete the task.

To take a picture, swipe forward on the frame with two fingers:

<figure>
<img src="/uploads/Wake-Up-Glass-and-Take-a-Picture.jpg" alt="">
<figcaption>Swipe forward with two-fingers to wake up Glass & take instant picture</figcaption>
</figure>

#### Suggestion: Instant Video Gesture

To record a video, swipe backwards on the frame with two fingers:

<figure>
<img src="/uploads/Wake-Up-Glass-and-Record-a-Video.jpg" alt="Swipe backwards with two-fingers to wake up Glass & record instant video">
<figcaption>Swipe backwards with two-fingers to wake up Glass & record instant video</figcaption>
</figure>

This would wake up the device and instantly record a 10-second video. To extend the video, swipe again backward with two fingers during the 10-second default duration.

#### Conclusion

Single repetitive actions are much faster to perform and memorize than a series of cognitive gestures.

The two-finger swipe gesture would also reduce the need for a manual shutter button. Fewer buttons mean less cognitive overhead for the user, and fewer moving parts.
